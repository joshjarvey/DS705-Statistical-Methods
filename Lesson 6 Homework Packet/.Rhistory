library(DS705data)
data("normtemp")
normtemp = na.omit(normtemp)
plot(normtemp$temp,normtemp$hr, main = "Heart Rate as a function of Body Temp",xlab = "Body Temp", ylab = "Heart Rate")
#create a linear regression between heart rate vs. temp.
model = lm(hr~temp, data = normtemp)
#grab the coefficients.
model$coefficients
#check summary of the model.
summary(model)
#generate a 95% confidence interval for the variables in my model.
confint(model)
#using the model, predict a temp of 98.6 degrees and provide a confidence interval.
predict(model, data.frame(temp=98.6), interval = "confidence")
#using the model, predict a temp of 98.6 degrees and provide a prediction interval.
predict(model, data.frame(temp=98.6), interval = "prediction")
#set up 4 rows of 4 columns. Give enough margin spacing with mar()
par(mfrow=c(3,2),mar=c(4,4,4,1))
#pull out the residuals from the model
resids = model$residuals
#pull out the fitted values from the model
pred = model$fitted.values
#pull out the independent variable, temp, from the dataset
temp = normtemp$temp
#plot independent variable vs. residuals
plot(temp, resids, main = "Temp (independent) vs. Residuals", xlab = "Temperature", ylab = "Residuals")
#plot fitted vs. residuals
plot(pred, resids, main = "Fitted vs. Residuals", xlab = "Fitted values", ylab = "Residuals")
#plot a histogram of the residuals
hist(resids, main = "Distribution of Residuals", xlab = "Residuals", ylab = "Frequency")
#boxplot of the residuals
boxplot(resids, main = "Distribution of Residuals", ylab = "Residuals")
#QQ Plot of the residuals
qqnorm(resids, main = "QQ Plot of Residuals")
qqline(resids)
#test for normality of the residuals
shapiro.test(resids)
#creating a "factorized" model using the independent variable
model_factor = lm(hr~factor(temp), data = normtemp)
#conducting an anova test on the base linear model and the factorized model. The base model is "nested" within the factorized model, so thats why this will work. This is an F-Teest for lack of fit. We hope to see a higher pvalue so we can keep with the basic linear model and keep it simple.
anova(model, model_factor)
#import the package to access bptest
library(lmtest)
#conduct the bptest() on the model to understand if the variances are equal vs. not equal. We want variances to be equal (and not reject the null).
bptest(model)
#completing a correlation test for the temp and heart rate. Sample correlation is listed below
cor.test(normtemp$temp,normtemp$hr, method = "pearson")$estimate
#pull the 95% confidence interval for the correlation.
cor.test(normtemp$temp,normtemp$hr, method = "pearson")$conf.int
(cor.test(normtemp$temp,normtemp$hr, method = "pearson")$estimate)^2
#calculating the spearman "Rank" correlation test.
cor.test(normtemp$temp,normtemp$hr, method = "spearman")$estimate
#put body temps into their own dataframe for prediction.
xplot = data.frame(temp)
#create 2 datasets - one predicting mean heart rate (confidence band), one predicting point estimate heart rate (prediction band)
fittedC = predict(model,xplot,interval = "confidence")
fittedP = predict(model,xplot,interval = "prediction")
#set the y limits of the plot to be the max of the upper value in the prediction band, and the minimum of the lower value in the prediction band.
ylimits = c(min(fittedP[,"lwr"]),max(fittedP[,"upr"]))
#plot the dataset and add a the model's linear line.
plot(normtemp$temp,normtemp$hr,ylim = ylimits, main = "Heart Rate vs. Body Temperature (w/confidence and prediction bands)", ylab = "Heart Rate", xlab = "Body Temperature")
abline(model)
#now add the "bands" using the upper values as the top and lower values as the bottom for each the confidence and prediction bands.
lines(xplot$temp, fittedC[,"lwr"], lty="dashed",col="darkgreen")
lines(xplot$temp, fittedC[,"upr"], lty="dashed",col="darkgreen")
lines(xplot$temp, fittedP[,"lwr"], lty="dotted",col="blue")
lines(xplot$temp, fittedP[,"upr"], lty="dotted",col="blue")
#load the data
library(DS705data)
data("JobProf")
#create a model with cross-products; show summary.
model2 = lm(y~x1+x2+x3+x1*x2+x1*x3+x2*x3, data = JobProf)
summary(model2)
#load the vif() function from the HH library. Use it to check for collinearity among variables.
library(HH)
vif(model2)
#create a 3rd model with just the first order terms.
model3 = lm(y~x1+x2+x3, data = JobProf)
summary(model3)
#use anova to test model3 (simpler model) vs. model 2 (all inclusive, more complex model).
anova(model3,model2)
#create a quadratic version of the x2 variable
x2sq = JobProf$x2^2
#fit a new model using the x2sq
model4 = lm(y~x1+x2+x3+x2sq, data = JobProf)
summary(model4)
#create a 5th model without the use of x2 (because it was non-significant)
model5 = lm(y~x1+x3, data = JobProf)
summary(model5)
#calculate confidence intervals for the model terms.
confint(model5, level = 0.90)
#create a dataframe of scores 99,112,105. Predict proficiency rating using these scores using model5, and give a prediction interval along with it.
predict(model5, data.frame(x1=99,x2=112,x3=105),interval = "prediction")
data("English")
model6 = lm(y~x1+x2,data = English)
summary(model6)
#create models of methods 1,2,3, with independent variables removes as necessary since it's categorical.
method1 = lm(y~x4, data = English)
method2 = lm(y~x4+x1+x1*x4, data = English)
method3 = lm(y~x4+x2+x2*x4, data = English)
summary(method1)
summary(method2)
summary(method3)
