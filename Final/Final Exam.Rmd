
---
title: "Final Exam"
author: "Josh Jarvey - DS 705"
output:
  word_document: default
  pdf_document: default
fontsize: 12pt
---

Unlike the Homework RMD files, this one doesn't contain all of the questions.  Rather we want you to read the questions on D2L and use this RMD file to record your R code that you used to answer each question.  This file must knit correctly.  After you submit the D2L quiz, then upload this RMD file and the knitted version of this file to the Final Exam dropbox on D2L.

## Questions 1-16

You do not need to submit any work with these questions.  Just answer them in D2L.

## Problem 1 - Questions 17-21

You're going to analyze the data in BirdPecks.rda and answer the questions in D2l.  Put all of your R in the chunk below:

```{r}
  #load in the dataset
library(DS705data)
data("BirdPecks")

  #create a boxplot of the number of pecks by feed group.
boxplot(pecks~group,data = BirdPecks, main = "Distribution of Chicken Pecks between Low Sodium and Regular Feed")
  #pull out the vector of pecks for low sodium feed
group1 = BirdPecks$pecks[BirdPecks$group==1]
  #pull out the vector of pecks for normal feed
group2 = BirdPecks$pecks[BirdPecks$group==2]
  #create a histogram of the chickens with low sodium feed
hist(group1, main = "Distribution of Chicken Pecks - Normal Feed", xlab = "Number of Pecks", ylab = "Count of Chickens")
  #create a histogram of the chickens with normal feed
hist(group2, main = "Distribution of Chicken Pecks - Low Sodium Feed", xlab = "Number of Pecks", ylab = "Count of Chickens")

  #test for normality in the low sodium feed
shapiro.test(group1)
  #test for normality in the normal feed
shapiro.test(group2)

  #complete a test with intervals for shift in median pecks between low sodium feed and normal feed - 90% confidence level 
wilcox.test(group1,group2, data = BirdPecks,conf.level = 0.90, conf.int = TRUE)

  #keeping things tidy
rm(group1, group2)
```

---

## Problem 2 - Questions 22-26

Analyze StrengthSpeed.rda and put your R below:

```{r}
  #load in the dataset
library(DS705data)
data("StrengthSpeed")
  #calculating the difference between sprint times after the regiment, minus sprint times before regiment
  #note: if the difference in speeds is NEGATIVE, then this means they performed the sprint faster.
difference = StrengthSpeed$after - StrengthSpeed$before

  #visually inspect the boxplot and histogram of the difference in sprint times - these normal normally distributed
boxplot(difference)
hist(difference)
  #generating a qqplot
qqnorm(difference)
qqline(difference)

  #test for normality, cannot reject the null
shapiro.test(difference)

  #after reviewing the conditions - we will use the paired t-test
  #we test that the after speed is less than the before speed (i.e. they've improved their sprint times)
t.test(StrengthSpeed$after,StrengthSpeed$before, alternative = "less", paired = TRUE)

  #keeping things tidy
rm(difference)
```

---

## Problem 3 - Questions 27-36

Analyze GroupHLT scores and put your R here:

```{r}
  #storing the HLT score data into vectors
win = c(79, 76, 74, 70, 81, 85, 73, 78, 69, 72, 83, 89, 72, 79, 75)
lose = c(78, 96, 85, 91, 77,103, 72, 93, 98, 86, 70, 110, 70, 91, 99)

  #creating a boxplot of HLT scores for win vs. lose
boxplot(win, lose, main = "HLT score distribution post football match", xlab="Win vs. Lose", ylab="HLT Score")
  #creating histograms of both win and lose
hist(win, main = "Distribution of HLT score - Win", xlab = "HLT Score")
hist(lose, main = "Distribution of HLT score - Lose", xlab = "HLT Score")
  #generating a qqplot
qqnorm(win)
qqline(win)
qqnorm(lose)
qqline(lose)
  #testing HLT score normality for win and lose. 
shapiro.test(win)
shapiro.test(lose)

  #complete the t.test to test if there is a difference in HLT scores between the win vs. lost population
t.test(win,lose,alternative = "two.sided")
  
  #generate a confidence interval for the lose population. 
t.test(lose, conf.level = 0.95)$conf.int

  #load the bootstrap package
library(boot)
  #create the auxiliary function to calculate the mean of the resamples.
bootMean <- function(x,i){
  return(mean(x[i]))
}
  #set seed for reproducability
set.seed(123)
  #complete 10000 bootstraps to create my sampling distribution for my parameter of interest (population mean for the "lose" group).
boot.object = boot(lose, bootMean, R=10000)
  #calculate the bca confidence interval
boot.ci(boot.object, conf = 0.95, type = "bca")

  #keeping things tidy
rm(lose, win, bootMean)

```

---

## Problem 4 - Questions 37-41

Analyze the data in treadware.rda and put your R here:

```{r}
library(DS705data)
library(car)
data("treadwear")
  #apply the mean() function to each "brand's" tirewear
tapply(treadwear$wear,treadwear$brand,mean)
  #apply the sd() function to each "brand's" tirewear
tapply(treadwear$wear,treadwear$brand,sd)

  #create a boxplot to visualize distributions and variances of tirewear by brand.
boxplot(wear~brand, data = treadwear, main = "Treadwear by Tire Brand")

  #apply the shapiro.test() function to each "brand's" tirewear to check normality
tapply(treadwear$wear,treadwear$brand,shapiro.test)

  #apply the levene test to check if variances are homogenous between sample groups. does not appear to be equal variance.
leveneTest(wear~brand, data = treadwear)

  #completing a "welch corrected" ANOVA. We select ANOVA because we have multiple populations. 
  #We select welch corrected (var.equal=FALSE) because the variances do not appear to be equal after looking at the samples. 
oneway.test(wear~brand, data = treadwear, var.equal = FALSE)

  #use the custom function from the DS705Data package, complete a Games-Howell test.
  #var.equals = FALSE means this is games-howell vs. the Tukey test.
  #adjust = one.step makes this a games-howell or tukey test.
onewayComp(wear~brand, data = treadwear, var.equal = FALSE, adjust = "one.step")$comp[,c(2,3,6,7)]
```

---

## Problem 5 - Questions 42-59

Analyze the data in diamond.rda and include your R here:

```{r}
  #load the diamond dataset and necessary libraries
library(DS705data)
library(lmtest)
data("diamond")

  #creating a scatterplot to visualize the relationship between price and carat. 
plot(price~carat, data = diamond, main = "Diamond Price as a function of Carat", xlab = "Weight (in Carat)", ylab = "Price (in $)")

  #create a linear regression model with price as a function of carat weight
model = lm(price~carat, data = diamond)
summary(model)

  #test the correlation coefficient between price and carat
with(diamond, cor.test(price, carat, conf.level = 0.99))

  #calculating the 95% CI for the regression model. 
confint(model)

  #create a histogram of the residuals
hist(model$residuals, main = "Distribution of model residuals", xlab = "Residuals")
  #create a QQ plot of the residuals
qqnorm(model$residuals)
qqline(model$residuals)
  #create a boxplot of the residuals
boxplot(model$residuals, main = "Distribution of model residuals", ylab = "Residuals")
  #test residuals for normality.
shapiro.test(model$residuals)

  #plot the residuals vs. fitted values to visualize variance. 
plot(model$fitted.values, model$residuals, main = "Residual Plot", ylab = "Residuals", xlab = "Fitted Values")

  #perform the BP test to check for equal variance. 
bptest(model)

  #calculate the R^2 (coefficient of determination). This is also calculated directly from the summary() command as well.
(cor.test(diamond$price,diamond$carat, method = "pearson")$estimate)^2

  #keeping things tidy
rm(model)
```

---

## Problem 6 - Questions 60- 66

Analyze the data in Shells.rda and include your R here:

```{r}
  #loading necessary libraries and dataset.
library(DS705data)
library(HH)
data("shells")

  #starting with a full model, do stepwise comparison using the "both" direction. 
  #AIC is -121.99
model = step(lm(Y~., data=shells), direction = "both", trace = FALSE)
  #checking the results of the model
summary(model)
  #checking the AIC of the model
extractAIC(model)
  #checking for collinearity between predictor variables. 
vif(model)

  #creating a 2nd order term using X2.
X2_sqrd = shells$X2^2
  #fit the second model that uses a second order term
modelB = lm(Y~X1 + X2 + X2_sqrd + X4 + X6, data = shells)
  #check results of the modelB
summary(modelB)
  #checking the AIC of the modelB
extractAIC(modelB)

### adjusted R^2 is within the summary statement....

  #keeping things tidy
rm(model,modelB, X2_sqrd)
```

---

## Problem 7 - Questions 67-70

Analyze the "Primary News Source for Americans" data described in the problem statement.  Put your R below:

```{r}
  #loading the data into R
observed = c(38,20,15,42)
proportion = c(0.45,0.18,0.16,0.21)
  #completing the chi-sq goodness of fit test to test the population proportions against stated proportions
test = chisq.test(x=observed,p=proportion); test
  #double checking expected values to ensure there is no category below 5. There are none.
test$expected

  #keeping things tidy
rm(test, observed, proportion)
```

---

## Problem 8 - Questions 71-75

Analyze the data in cheese.rda and put your R below:

```{r}
  #load the required library and dataset.
library(DS705data)
data("cheese")

  #create a new factor variable that puts not acceptable as the 0, and acceptable as 1 (since alphabetically, it was mismatched)
cheese$taste2 = ifelse(cheese$taste=="Not Acceptable",0,1)

  #create a logistic regression model with taste2 as a function of acetic and person
model = glm(taste2~acetic + person, data = cheese, family = "binomial")
summary(model)

  #convert the logit number to an odds ratio number. 
exp(model$coefficients[2])

  #using the model, predict the probability an "acceptable" response.
newdata = data.frame(acetic=6,person="Child")
predict(model,newdata,type = "response")

  #using the standard error, we can create a confidence interval for this prediction.
out = predict(model,newdata,se.fit = TRUE)
  #CI = 95%
C = 0.95
crit = qnorm(1-(1-C)/2)

  #create the CI bounds and display.
lower = exp(out$fit-crit*out$se.fit)/(1+exp(out$fit-crit*out$se.fit))
upper = exp(out$fit+crit*out$se.fit)/(1+exp(out$fit+crit*out$se.fit))
c(lower,upper)

  #keeping things tidy
rm(model,out,C,crit,lower,upper,newdata)
```

---

## Problem 9 - Questions 76-90

Analyze the data in careerbarrier.rda and put your R below:

```{r}
  #loading the required libraries and the dataset
library(DS705data)
library(psych)
data("careerbarrier")
  #creating a correlation matrix using the variables from the dataset
matrx = cor(careerbarrier)
  #testing if the correlation matrix is the identity matrix, which would indicate factor analysis is not useful here.
cortest.bartlett(matrx,n=76)

  #now that factor analysis shows promise, conducting KMO() analysis to calculate the MSA score to see overall score, but also if there are any variables that stand on their own and dropped from the factor analysis.
KMO(matrx)

  #"money" has a MSA score of <0.50, so we drop it and perform the KMO() analysis again.
matrx2 = cor(careerbarrier[,-1])
KMO(matrx2)

  #create a scree plot to check "knee" (where the line starts to even out - 3), and number of eigenvalues greater than 1 (the dotted line) - 5.
output = princomp(matrx2, cor = TRUE)
plot(output, type = "lines")
abline(h=1, lty=2)

  #perform the PCA using the varimax rotation. Suppress factor loadings under 0.50, and sort them by the most variance first. 
fa.out = principal(matrx2,nfactors = 5, rotate = "varimax")
print.psych(fa.out,cut = 0.5, sort = TRUE)

  #keeping things tidy
rm(matrx,matrx2,output,fa.out)
```

---

## Problem 10 - Questions 91-98

Analyze the data on seat postion vs. nausea described in the problem.  Put your R below:

```{r}
  #loading necessary packages
library(mosaic)
  #create a matrix to store the data within. first row is nausea, second row is no nausea. 
bus = matrix(c(98,110,161,264,321,280),nrow = 2, byrow=TRUE)
  #label the columns and rows accordingly.
colnames(bus) = c("Front", "Middle", "Rear")
rownames(bus) = c("Nausea", "No Nausea")
  #add sum margins to the table so we can perform the chisq test for independence.
addmargins(bus)

  #perform the chisq test of independence.
result = chisq.test(bus); result
  #double checking there are no expected counts less than 5, otherwise we'd need to use fisher exact test. 
result$expected

  #setting up the difference in front vs back. for nausea and no nausea 
diff_nausea = abs(bus[1,1] - bus[1,3])
diff_no_nausea = abs(bus[2,1] - bus[2,3])
diff = c(diff_nausea,diff_no_nausea)
  #pulling totals in own vector
total = c(369,865)

  #performing the prop test in differences between front vs. back for no nausea vs. nausea respectively. 
prop.test(diff,total, correct = FALSE, conf.level = 0.90)

  #create a matrix to store the data within. first row is nausea, second row is no nausea. 
bus2 = matrix(c(98,161,264,280),nrow = 2, byrow=TRUE)
  #label the columns and rows accordingly.
colnames(bus2) = c("Rear", "Front")
rownames(bus2) = c("Nausea", "No Nausea")
  #add sum margins to the table so we can calculate the odds ratio.
addmargins(bus2)

  #compute the odds ratio using the mosaic package. 
oddsRatio(bus2, verbose = TRUE)

  #keeping things tidy
rm(diff,diff_nausea, diff_no_nausea,total,bus,bus2,result)
```

---

## Question 99

Make sure both this RMD and the resulting knitted Word document are uploaded to the Dropbox "Final Exam R Code."
