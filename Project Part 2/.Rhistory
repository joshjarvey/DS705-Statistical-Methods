imputation = mice(loans, seed = seed)
#iterate through each missing value and calculate the average of the imputed set, replace NA with the imputed value.
for(i in 1:length(index_NA)){
sum = 0
sum = sum + imputation$imp$bcOpen$`1`[i]
sum = sum + imputation$imp$bcOpen$`2`[i]
sum = sum + imputation$imp$bcOpen$`3`[i]
sum = sum + imputation$imp$bcOpen$`4`[i]
sum = sum + imputation$imp$bcOpen$`5`[i]
df$bcOpen[index_NA[i]] = sum/5
}
return(df)
}
loans = impute_bcOpen(loans, seed = 123456)
par(mfrow=c(1,2),mar=c(4,4,4,1))
hist(loans$income, main = "Distribution of Income", xlab = "Dollars ($)")
hist(log(loans$income), main = "Distribution of log(Income)", xlab = "Dollars (Log $)")
par(mfrow=c(1,1))
loans$income = log(loans$income)
#set up 4 rows of 4 columns. Give enough margin spacing with mar()
par(mfrow=c(5,4),mar=c(4,4,4,1))
#Line 1: amount & totalBal
hist(loans$amount, main = "amount", xlab = "")
hist(log(loans$amount), main = "log(amount)", xlab = "")
hist(loans$totalBal, main = "totalBal", xlab = "")
hist(log(loans$totalBal), main = "log(totalBal)", xlab = "")
#Line 2: totalRevLim & bcOpen
hist(loans$totalRevLim, main = "totalRevLim", xlab = "")
hist(log(loans$totalRevLim), main = "log(totalRevLim)", xlab = "")
hist(loans$bcOpen, main = "bcOpen", xlab = "")
hist(log(loans$bcOpen), main = "log(bcOpen)", xlab = "")
#Line 3: totalLim & total RevBal
hist(loans$totalLim, main = "totalLim", xlab = "")
hist(log(loans$totalLim), main = "log(totalLim)", xlab = "")
hist(loans$totalRevBal, main = "totalRevBal", xlab = "")
hist(log(loans$totalRevBal), main = "log(totalRevBal)", xlab = "")
#Line 4: totalBcLim & totalILim
hist(loans$totalBcLim, main = "totalBcLim", xlab = "")
hist(log(loans$totalBcLim), main = "log(totalBcLim)", xlab = "")
hist(loans$totalIlLim, main = "totalIlLim", xlab = "")
hist(log(loans$totalIlLim), main = "log(totalIlLim)", xlab = "")
#Line 5: avgBal
hist(loans$avgBal, main = "avgBal", xlab = "")
hist(log(loans$avgBal), main = "log(avgBal)", xlab = "")
#reset my graphs back to a 1x1.
par(mfrow=c(1,1))
#creating a list of columns to transform
cols_to_transform = c("totalBal","totalRevLim","bcOpen","totalLim","totalRevBal","totalBcLim","totalIlLim","avgBal")
#because log(0) = -inf, add +1 to the values first just to ensure this doesnt occur. It's by such a small factor that it wont be a large impact on the results.
loans[cols_to_transform] = loans[cols_to_transform]+1
#applying the log transform to the columns.
loans[cols_to_transform] = lapply(loans[cols_to_transform], log)
rm(cols_to_transform)
#create a side by side box plot that shows the distribution of loan amounts by the outcome
bx_amount=gf_boxplot(amount~outcome, data=loans, color=~outcome, xlab="Loan Outcome", ylab="Loan Amount ($)", title='Distribution of Loan "Amount"')
#create a side by side box plot that shows the distribution of loan amounts by the outcome
bx_rate=gf_boxplot(rate~outcome, data=loans, color=~outcome, xlab="Loan Outcome", ylab="Loan Rate (%)", title='Distribution of Loan "Rate"')
#use ggarrange to set ggplots next to each other
ggarrange(bx_amount,bx_rate, ncol = 2, nrow = 1)
#test if the median dollar amount of loans in the bad loan group is greater than the median dollar amount of loans in the good loan group.
#p1 = The median dollar amount of loans in the bad loan group
#p2 = The median dollar amount of loans in the good loan group
#H0: p1 <= p2
#H_a: p1 > p2
#alpha = 0.05
wilcox.test(loans$amount~loans$outcome, alternative = "greater", conf.int = TRUE)
#test if the median of percentage rates in the bad loan group is greater than the median of percentage rates in the good loan group.
#p1 = The median rate in the bad loan group
#p2 = The median rate in the good loan group
#H0: p1 <= p2
#H_a: p1 > p2
#alpha = 0.05
wilcox.test(loans$rate~loans$outcome, alternative = "greater", conf.int = TRUE)
#create a side by side bar chart to see the distribution of loan term by outcome.
bar_grade=gf_bar(~grade, data = loans, fill = ~outcome, position = position_dodge(), title = 'Distribution of Loan "Grade"')
#create a side by side bar chart to see the distribution of loan term by outcome.
bar_term=gf_bar(~term, data = loans, fill = ~outcome, position = position_dodge(), title = 'Distribution of Loan "Term"')
#use ggarrange to set ggplots next to each other
ggarrange(bar_grade, bar_term, ncol = 2, nrow = 1)
#test if the number of "bad" loans is equal across each loan grade, or not equal to each other.
#p1 = The proportion of bad outcomes for loan grade "A"
#p2 = The proportion of bad outcomes for loan grade "B"
#p3 = The proportion of bad outcomes for loan grade "C"
#p4 = The proportion of bad outcomes for loan grade "D"
#p5 = The proportion of bad outcomes for loan grade "E or less"
#H0: p1 = p2 = p3 = p4 = p5
#H_a: p1 <> p2 <> p3 <> p4 <> p5
#alpha = 0.05
#pull the counts of bad loans per each loan grade.
bad_A = nrow(loans[loans$outcome == "Bad" & loans$grade == "A",])
bad_B = nrow(loans[loans$outcome == "Bad" & loans$grade == "B",])
bad_C = nrow(loans[loans$outcome == "Bad" & loans$grade == "C",])
bad_D = nrow(loans[loans$outcome == "Bad" & loans$grade == "D",])
bad_E = nrow(loans[loans$outcome == "Bad" & loans$grade == "E or less",])
#create a matrix of grade, count, and equal proportions
grades = matrix(c("A",bad_A,0.20,"B",bad_B,0.20,"C",bad_C,0.20,"D",bad_D,0.20,"E or Less",bad_E,0.20), ncol = 3, byrow = TRUE)
colnames(grades) = c("Grade","Frequency of Bad","equaldistribution")
#run the chi-squared goodness of fit test
grades_test = chisq.test(as.numeric(grades[,2]), p = as.numeric(grades[,3]))
#check expected values -> they are greater than 5 per category.
grades_test$expected
#review results
grades_test
#test if the proportion of bad loans in 36 month term is less than the proportion of bad loans in the 60 month term.
#p1 = The proportion of bad loans in the 36 month term
#p2 = The proportion of bad loans in the 60 month term
#H0: p1 >= p2
#H_a: p1 < p2
#alpha = 0.05
#get the number of bad records from 36 month term
bad_36 = nrow(loans[loans$outcome == "Bad" & loans$term == "36 months",])
#get the number of good records from 36 month term
good_36 = nrow(loans[loans$outcome == "Good" & loans$term == "36 months",])
#get the number of bad records from 36 month term
bad_60 = nrow(loans[loans$outcome == "Bad" & loans$term == "60 months",])
#get the number of good records from 36 month term
good_60 = nrow(loans[loans$outcome == "Good" & loans$term == "60 months",])
#create a matrix of bad/good for 36/60 months
term = matrix(c(bad_36,good_36,bad_60,good_60), ncol = 2, byrow = TRUE)
rownames(term) = c("36 months","60 months")
colnames(term) = c("Bad","Good")
#data is prepped, so run prop.test to check if: proportion of bad loans in the 36month term < proportion of bad loans in the 60month term.
prop.test(term, alternative = "less", correct = TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans[,1], SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(data, sample == TRUE)
library(caTools)
set.seed(101)
sample = sample.split(loans, SplitRatio = .80)
train = subset(loans, sample == TRUE)
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
picked = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[picked,]
test =loans[-picked,]
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
training_data = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[training_data,]
test =loans[-training_data,]
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
training_data = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[training_data,]
test =loans[-training_data,]
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
training_data = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[training_data,]
test =loans[-training_data,]
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
training_data = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[training_data,]
test =loans[-training_data,]
sample_size = floor(0.8*nrow(loans))
set.seed(777)
# randomly split data in r
training_data = sample(seq_len(nrow(loans)),size = sample_size)
train =loans[training_data,]
test =loans[-training_data,]
detach("package:caTools", unload = TRUE)
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
knitr::opts_chunk$set(fig.width = 4, fig.height = 4)
lapply(c("readr","dplyr","car","mice","ggformula","ggpubr"), require, character.only = TRUE)
#load the data
loans = read_csv("loans50k.csv")
loans = loans[loans$status %in% c("Fully Paid", "Charged Off", "Default"),]
loans = loans %>% mutate(outcome = as.factor(if_else(status == "Fully Paid","Good","Bad")))
loans = subset(loans, select = -status)
loans = subset(loans, select = -c(loanID,employment,verified,state,debtIncRat,revolRatio,totalAcc,totalPaid,bcRatio))
str(loans)
loans = mutate_at(loans, vars(term,grade,length,home,reason), as.factor)
par(mfrow=c(2,3),mar=c(4,3,3,1))
barplot(table(loans$term), main = "Loan Term")
barplot(table(loans$grade), main = "Loan Grade")
barplot(table(loans$length), las=2, main = "Employment Length")
barplot(table(loans$home), main = "Living Type")
barplot(table(loans$reason), las=2, cex.names = 0.9, main = "Loan Reason")
loans$grade = recode(loans$grade,"c('E','F','G')='E or less'")
loans$length = recode(loans$length,"c('< 1 year','1 year','2 years','3 years','4 years')='0-4 years';c('5 years','6 years','7 years','8 years','9 years')='5-9 years'")
loans$reason = recode(loans$reason,"'credit_card'='Credit Card';'debt_consolidation'='Debt Consolidation'; c('home_improvement','house','moving','renewable_energy')='Home Expense'; c('car','major_purchase','medical','other','small_business','vacation','wedding')='Other'")
loans = loans[which(loans$length != "n/a"),]
impute_bcOpen <- function(df, seed){
#create a vector of the indices that are "NA"
index_NA = which(is.na(df$bcOpen))
#complete the imputation process
imputation = mice(loans, seed = seed)
#iterate through each missing value and calculate the average of the imputed set, replace NA with the imputed value.
for(i in 1:length(index_NA)){
sum = 0
sum = sum + imputation$imp$bcOpen$`1`[i]
sum = sum + imputation$imp$bcOpen$`2`[i]
sum = sum + imputation$imp$bcOpen$`3`[i]
sum = sum + imputation$imp$bcOpen$`4`[i]
sum = sum + imputation$imp$bcOpen$`5`[i]
df$bcOpen[index_NA[i]] = sum/5
}
return(df)
}
loans = impute_bcOpen(loans, seed = 123456)
par(mfrow=c(1,2),mar=c(4,4,4,1))
hist(loans$income, main = "Distribution of Income", xlab = "Dollars ($)")
hist(log(loans$income), main = "Distribution of log(Income)", xlab = "Dollars (Log $)")
par(mfrow=c(1,1))
loans$income = log(loans$income)
#set up 4 rows of 4 columns. Give enough margin spacing with mar()
par(mfrow=c(5,4),mar=c(4,4,4,1))
#Line 1: amount & totalBal
hist(loans$amount, main = "amount", xlab = "")
hist(log(loans$amount), main = "log(amount)", xlab = "")
hist(loans$totalBal, main = "totalBal", xlab = "")
hist(log(loans$totalBal), main = "log(totalBal)", xlab = "")
#Line 2: totalRevLim & bcOpen
hist(loans$totalRevLim, main = "totalRevLim", xlab = "")
hist(log(loans$totalRevLim), main = "log(totalRevLim)", xlab = "")
hist(loans$bcOpen, main = "bcOpen", xlab = "")
hist(log(loans$bcOpen), main = "log(bcOpen)", xlab = "")
#Line 3: totalLim & total RevBal
hist(loans$totalLim, main = "totalLim", xlab = "")
hist(log(loans$totalLim), main = "log(totalLim)", xlab = "")
hist(loans$totalRevBal, main = "totalRevBal", xlab = "")
hist(log(loans$totalRevBal), main = "log(totalRevBal)", xlab = "")
#Line 4: totalBcLim & totalILim
hist(loans$totalBcLim, main = "totalBcLim", xlab = "")
hist(log(loans$totalBcLim), main = "log(totalBcLim)", xlab = "")
hist(loans$totalIlLim, main = "totalIlLim", xlab = "")
hist(log(loans$totalIlLim), main = "log(totalIlLim)", xlab = "")
#Line 5: avgBal
hist(loans$avgBal, main = "avgBal", xlab = "")
hist(log(loans$avgBal), main = "log(avgBal)", xlab = "")
#reset my graphs back to a 1x1.
par(mfrow=c(1,1))
#creating a list of columns to transform
cols_to_transform = c("totalBal","totalRevLim","bcOpen","totalLim","totalRevBal","totalBcLim","totalIlLim","avgBal")
#because log(0) = -inf, add +1 to the values first just to ensure this doesnt occur. It's by such a small factor that it wont be a large impact on the results.
loans[cols_to_transform] = loans[cols_to_transform]+1
#applying the log transform to the columns.
loans[cols_to_transform] = lapply(loans[cols_to_transform], log)
rm(cols_to_transform)
#create a side by side box plot that shows the distribution of loan amounts by the outcome
bx_amount=gf_boxplot(amount~outcome, data=loans, color=~outcome, xlab="Loan Outcome", ylab="Loan Amount ($)", title='Distribution of Loan "Amount"')
#create a side by side box plot that shows the distribution of loan amounts by the outcome
bx_rate=gf_boxplot(rate~outcome, data=loans, color=~outcome, xlab="Loan Outcome", ylab="Loan Rate (%)", title='Distribution of Loan "Rate"')
#use ggarrange to set ggplots next to each other
ggarrange(bx_amount,bx_rate, ncol = 2, nrow = 1)
#test if the median dollar amount of loans in the bad loan group is greater than the median dollar amount of loans in the good loan group.
#p1 = The median dollar amount of loans in the bad loan group
#p2 = The median dollar amount of loans in the good loan group
#H0: p1 <= p2
#H_a: p1 > p2
#alpha = 0.05
wilcox.test(loans$amount~loans$outcome, alternative = "greater", conf.int = TRUE)
#test if the median of percentage rates in the bad loan group is greater than the median of percentage rates in the good loan group.
#p1 = The median rate in the bad loan group
#p2 = The median rate in the good loan group
#H0: p1 <= p2
#H_a: p1 > p2
#alpha = 0.05
wilcox.test(loans$rate~loans$outcome, alternative = "greater", conf.int = TRUE)
#create a side by side bar chart to see the distribution of loan term by outcome.
bar_grade=gf_bar(~grade, data = loans, fill = ~outcome, position = position_dodge(), title = 'Distribution of Loan "Grade"')
#create a side by side bar chart to see the distribution of loan term by outcome.
bar_term=gf_bar(~term, data = loans, fill = ~outcome, position = position_dodge(), title = 'Distribution of Loan "Term"')
#use ggarrange to set ggplots next to each other
ggarrange(bar_grade, bar_term, ncol = 2, nrow = 1)
#test if the number of "bad" loans is equal across each loan grade, or not equal to each other.
#p1 = The proportion of bad outcomes for loan grade "A"
#p2 = The proportion of bad outcomes for loan grade "B"
#p3 = The proportion of bad outcomes for loan grade "C"
#p4 = The proportion of bad outcomes for loan grade "D"
#p5 = The proportion of bad outcomes for loan grade "E or less"
#H0: p1 = p2 = p3 = p4 = p5
#H_a: p1 <> p2 <> p3 <> p4 <> p5
#alpha = 0.05
#pull the counts of bad loans per each loan grade.
bad_A = nrow(loans[loans$outcome == "Bad" & loans$grade == "A",])
bad_B = nrow(loans[loans$outcome == "Bad" & loans$grade == "B",])
bad_C = nrow(loans[loans$outcome == "Bad" & loans$grade == "C",])
bad_D = nrow(loans[loans$outcome == "Bad" & loans$grade == "D",])
bad_E = nrow(loans[loans$outcome == "Bad" & loans$grade == "E or less",])
#create a matrix of grade, count, and equal proportions
grades = matrix(c("A",bad_A,0.20,"B",bad_B,0.20,"C",bad_C,0.20,"D",bad_D,0.20,"E or Less",bad_E,0.20), ncol = 3, byrow = TRUE)
colnames(grades) = c("Grade","Frequency of Bad","equaldistribution")
#run the chi-squared goodness of fit test
grades_test = chisq.test(as.numeric(grades[,2]), p = as.numeric(grades[,3]))
#check expected values -> they are greater than 5 per category.
grades_test$expected
#review results
grades_test
#test if the proportion of bad loans in 36 month term is less than the proportion of bad loans in the 60 month term.
#p1 = The proportion of bad loans in the 36 month term
#p2 = The proportion of bad loans in the 60 month term
#H0: p1 >= p2
#H_a: p1 < p2
#alpha = 0.05
#get the number of bad records from 36 month term
bad_36 = nrow(loans[loans$outcome == "Bad" & loans$term == "36 months",])
#get the number of good records from 36 month term
good_36 = nrow(loans[loans$outcome == "Good" & loans$term == "36 months",])
#get the number of bad records from 36 month term
bad_60 = nrow(loans[loans$outcome == "Bad" & loans$term == "60 months",])
#get the number of good records from 36 month term
good_60 = nrow(loans[loans$outcome == "Good" & loans$term == "60 months",])
#create a matrix of bad/good for 36/60 months
term = matrix(c(bad_36,good_36,bad_60,good_60), ncol = 2, byrow = TRUE)
rownames(term) = c("36 months","60 months")
colnames(term) = c("Bad","Good")
#data is prepped, so run prop.test to check if: proportion of bad loans in the 36month term < proportion of bad loans in the 60month term.
prop.test(term, alternative = "less", correct = TRUE)
set.seed(777)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(123)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(123)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(123)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
set.seed(123)
training_data = sample(seq_len(nrow(loans)),size = floor(0.80*nrow(loans)))
train =loans[training_data,]
test =loans[-training_data,]
View(train)
model = glm(outcome~., data = train, family = "binomial")
summary(model)
View(train)
#building a full model (for the upper limit)
full2model = glm(outcome~., data = train, family = "binomial")
#building a null model (or starting point, for the lower bounds) so the "step forward" can add to it.
null2model = glm(outcome~1, data = train, family = "binomial")
#starting with the null model, add one variable at a time until you bottom out on the AIC score.
#dont forget make the lower and upper a LIST type.
step(null2model, scope = list(lower = null2model, upper = full2model), direction = "forward")
vif(model)
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train, nvmax = 8)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
plot(model)
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
model2 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
amount + rate + totalIlLim + inq6mth, family = "binomial",
data = train)
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
model2 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
amount + rate + totalIlLim + inq6mth, family = "binomial",
data = train)
summary(model2)
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(outcome~.,data = train)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
model2 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
amount + rate + totalIlLim + inq6mth, family = "binomial",
data = train)
plot(model2)
vif(model2)
vif(model2)
summary(model2)
vif(model2)
summary(model2)
model3 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home + rate + totalIlLim + inq6mth, family = "binomial",
data = train)
vif(model3)
plot(model3)
vif(model2)
model3 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home + rate + totalIlLim + inq6mth, family = "binomial",
data = train)
vif(model3)
step(model3, scope = . ~ .^2, direction = 'forward')
model4 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
rate + totalIlLim + inq6mth + term:totalLim + payment:delinq2yr +
totalRevBal:payment + grade:rate + accOpen24:bcOpen + term:home +
accOpen24:rate + delinq2yr:rate + payment:bcOpen + totalLim:bcOpen +
totalLim:rate + term:income + totalRevBal:totalIlLim + totalLim:totalIlLim +
term:rate + accOpen24:inq6mth + home:totalIlLim + payment:inq6mth,
family = "binomial", data = train)
model4 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
rate + totalIlLim + inq6mth + term:totalLim + payment:delinq2yr +
totalRevBal:payment + grade:rate + accOpen24:bcOpen + term:home +
accOpen24:rate + delinq2yr:rate + payment:bcOpen + totalLim:bcOpen +
totalLim:rate + term:income + totalRevBal:totalIlLim + totalLim:totalIlLim +
term:rate + accOpen24:inq6mth + home:totalIlLim + payment:inq6mth,
family = "binomial", data = train)
summary(model4)
model4 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
rate + totalIlLim + inq6mth + term:totalLim + payment:delinq2yr +
totalRevBal:payment + grade:rate + accOpen24:bcOpen + term:home +
accOpen24:rate + delinq2yr:rate + payment:bcOpen + totalLim:bcOpen +
totalLim:rate + term:income + totalRevBal:totalIlLim + totalLim:totalIlLim +
term:rate + accOpen24:inq6mth + home:totalIlLim + payment:inq6mth,
family = "binomial", data = train)
summary(model3)
summary(model4)
model4 = glm(formula = outcome ~ grade + term + accOpen24 + totalLim +
totalRevBal + income + payment + delinq2yr + bcOpen + home +
rate + totalIlLim + inq6mth + term:totalLim + payment:delinq2yr +
totalRevBal:payment + grade:rate + accOpen24:bcOpen + term:home +
accOpen24:rate + delinq2yr:rate + payment:bcOpen + totalLim:bcOpen +
totalLim:rate + term:income + totalRevBal:totalIlLim + totalLim:totalIlLim +
term:rate + accOpen24:inq6mth + home:totalIlLim + payment:inq6mth,
family = "binomial", data = train)
summary(model3)
summary(model4)
plot(model4)
