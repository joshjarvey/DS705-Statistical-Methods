gf_histogram(~model_f$residuals)
hist(model_f$residuals)
qqnorm(model_f$residuals)
qqline(model_f$residuals)
boxplot(model_f$residuals)
shapiro.test(model_f$residuals)
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals)
qqline(model_f$residuals)
boxplot(model_f$residuals)
shapiro.test(model_f$residuals)
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
shapiro.test(model_f$residuals)
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, ylab = "Count", main = "Distribution of Residuals for Model_F")
shapiro.test(model_f$residuals)
plot(model_f)
plot(model_f[1])
plot(model_f)[1]
plot(model_f$residuals, model_f$fitted.values
plot(model_f$residuals, model_f$fitted.values)
plot(model_f$fitted.values, model_f$residuals)
#create a residual plot of residuals vs. fitted values.
plot(model_f$fitted.values, model_f$residuals, xlab="Fitted Values", ylab = "Residuals", main = "Residual Plot for Model_F")
library(lmtest)
library(lmtest)
bptest(model_f)
library(DS705data)
data("rowtime")
summary(rowtime)
library(leaps)
allmodels=regsubsets(racetime~.,data = rowtime, nvmax = 8)
summary(allmodels)
plot(allmodels, scale = "adjr2")
step(lm(racetime~., data=rowtime), direction = "backward")
nullmodel = lm(racetime~1, data = rowtime)
fullmodel = lm(racetime~., data = rowtime)
step(nullmodel,scope = list(lower=nullmodel, upper=fullmodel), direction = "forward")
#regsubsets w/8 variables
extractAIC(lm(formula = racetime~calfcir+biceps+bestvj+legpower+meso+ecto+expvarsity+preexper, data=rowtime))
#step backward (9 variables)
extractAIC(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
#step forward (8 variables)
extractAIC(lm(formula = racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj, data=rowtime))
#loading the car package for the vif() function
library(car)
#checking the vif scores of the independent variables. greater than 10 suggests a collinearity problem.
vif(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
# The code in this chunk is provided for students
library(DS705data)
data("rowtime")
pairs(rowtime[c(1,2,3,4)])
pairs(rowtime[c(1,5,6,7)])
pairs(rowtime[c(1,8,9,10)])
pairs(rowtime[c(1,11,12,13,14)])
pairs(rowtime[c(1,15,16,17,18)])
#storing the results of the forward step() model into a variable
model = lm(racetime~estffm + expvarsity + tall + preexper + biceps + meso + calfcir + bestvj, data = rowtime)
#using that model as a starting point, check the combination of all interaction terms to see if they add additional value.
step(model, scope = .~.*., direction = "forward")
#create a summary of the new model with the two additional interaction terms.
model_f = lm(racetime ~ estffm + expvarsity + tall + preexper + biceps + meso + calfcir + bestvj + tall:calfcir + estffm:bestvj, data = rowtime)
summary(model_f)
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, ylab = "Count", main = "Distribution of Residuals for Model_F")
shapiro.test(model_f$residuals)
#create a residual plot of residuals vs. fitted values.
plot(model_f$fitted.values, model_f$residuals, xlab="Fitted Values", ylab = "Residuals", main = "Residual Plot for Model_F")
library(lmtest)
bptest(model_f)
data("farmpond")
data("farmpond")
model2 = glm(RICH~., data = farmpond, family = "binomial")
data("farmpond")
model2 = glm(RICH~., data = farmpond, family = "binomial")
summary(model2)
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
full2model = glm(RICH~., data = farmpond, family = "binomial")
null2model = glm(RICH~1, data = farmpond, family = "binomial")
step(null2model, scope = (lower = null2model, upper = model2), direction = "forward")
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
full2model = glm(RICH~., data = farmpond, family = "binomial")
null2model = glm(RICH~1, data = farmpond, family = "binomial")
step(null2model, scope = (lower = null2model, upper = full2model), direction = "forward")
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
full2model = glm(RICH~., data = farmpond, family = "binomial")
null2model = glm(RICH~1, data = farmpond, family = "binomial")
step(null2model, scope = list(lower = null2model, upper = full2model), direction = "forward")
# use for beamer
knitr::opts_chunk$set(fig.width=3, fig.height=1.5, fig.align='center',warning=FALSE, message=FALSE)
library(knitr)
library(pscl)
library(ResourceSelection)
library(DS705data)
data(farmpond)
# use for word
# knitr::opts_chunk$set(fig.width=4, fig.height=3,warning=FALSE, message=FALSE)
#farmpond$RICH <- farmpond$rich
rich.out.full <- glm(RICH~FISH*TOTNITR*POND_AREA,data=farmpond,family="binomial")
# trim the output to fit on one slide
require(utils)
tmp <- noquote(
capture.output(
step(rich.out.full)
)
)
write.table(tmp[1:6],quote=F,row.names=F,col.names=F)
rich.out.full <- glm(RICH~FISH*TOTNITR*POND_AREA,data=farmpond,family="binomial")
# trim the output to fit on one slide
require(utils)
tmp <- noquote(
capture.output(
step(rich.out.full)
)
)
write.table(tmp[34:39],quote=F,row.names=F,col.names=F)
rich.out <- glm(RICH~FISH + TOTNITR,data=farmpond,family="binomial")
rich.out2 <- glm(RICH~FISH*TOTNITR + POND_AREA,data=farmpond,family="binomial")
anova(rich.out,rich.out2,test="Chi")
# use for beamer
knitr::opts_chunk$set(fig.width=3, fig.height=1.5, fig.align='center',warning=FALSE, message=FALSE)
library(knitr)
library(pscl)
library(ResourceSelection)
library(DS705data)
data(farmpond)
# use for word
# knitr::opts_chunk$set(fig.width=4, fig.height=3,warning=FALSE, message=FALSE)
#farmpond$RICH <- farmpond$rich
rich.out.full <- glm(RICH~FISH*TOTNITR*POND_AREA,data=farmpond,family="binomial")
# trim the output to fit on one slide
require(utils)
tmp <- noquote(
capture.output(
step(rich.out.full)
)
)
write.table(tmp[1:6],quote=F,row.names=F,col.names=F)
rich.out.full <- glm(RICH~FISH*TOTNITR*POND_AREA,data=farmpond,family="binomial")
# trim the output to fit on one slide
require(utils)
tmp <- noquote(
capture.output(
step(rich.out.full)
)
)
write.table(tmp[34:39],quote=F,row.names=F,col.names=F)
rich.out <- glm(RICH~FISH + TOTNITR,data=farmpond,family="binomial")
rich.out2 <- glm(RICH~FISH*TOTNITR + POND_AREA,data=farmpond,family="binomial")
anova(rich.out,rich.out2,test="Chi")
predprob <- fitted(rich.out) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
#load the data and review a summary of the variables.
library(DS705data)
data("rowtime")
summary(rowtime)
#import the regsubsets() function from the leaps library
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(racetime~.,data = rowtime, nvmax = 8)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
#start with a "full" model denoted by y~.
#then do a backward step to remove variables from the equation until a best is reached.
step(lm(racetime~., data=rowtime), direction = "backward")
#to begin the "forward" step function, we set a "null" model which is the y~1
nullmodel = lm(racetime~1, data = rowtime)
#we set a "full" model to be the "cap" for the forward step function y~.
fullmodel = lm(racetime~., data = rowtime)
#starting with the null model, add variables one at a time and test their impact, within the bounds of the lower and upper limits.
step(nullmodel,scope = list(lower=nullmodel, upper=fullmodel), direction = "forward")
#regsubsets w/8 variables
extractAIC(lm(formula = racetime~calfcir+biceps+bestvj+legpower+meso+ecto+expvarsity+preexper, data=rowtime))
#step backward (9 variables)
extractAIC(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
#step forward (8 variables)
extractAIC(lm(formula = racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj, data=rowtime))
#loading the car package for the vif() function
library(car)
#checking the vif scores of the independent variables. greater than 10 suggests a collinearity problem.
vif(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
# The code in this chunk is provided for students
library(DS705data)
data("rowtime")
pairs(rowtime[c(1,2,3,4)])
pairs(rowtime[c(1,5,6,7)])
pairs(rowtime[c(1,8,9,10)])
pairs(rowtime[c(1,11,12,13,14)])
pairs(rowtime[c(1,15,16,17,18)])
#storing the results of the forward step() model into a variable
model = lm(racetime~estffm + expvarsity + tall + preexper + biceps + meso + calfcir + bestvj, data = rowtime)
#using that model as a starting point, check the combination of all interaction terms to see if they add additional value.
#the first . means all variables. the * means interaction, and the second . means all teams. So to summarize, check all terms interactions with all terms.
step(model, scope = .~.*., direction = "forward")
#create a summary of the new model with the two additional interaction terms.
model_f = lm(racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj+tall:calfcir+estffm:bestvj, data=rowtime)
summary(model_f)
#create a histogram, qqplot, and boxplot of the residuals.
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, ylab = "Count", main = "Distribution of Residuals for Model_F")
#check normality of the residuals with the shapiro test.
shapiro.test(model_f$residuals)
#create a residual plot of residuals vs. fitted values.
plot(model_f$fitted.values, model_f$residuals, xlab="Fitted Values", ylab = "Residuals", main = "Residual Plot for Model_F")
#load in the lmtest library
library(lmtest)
#run the equal variance test.
bptest(model_f)
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
#building a full model (for the upper limit)
full2model = glm(RICH~., data = farmpond, family = "binomial")
#building a null model (or starting point, for the lower bounds) so the "step forward" can add to it.
null2model = glm(RICH~1, data = farmpond, family = "binomial")
#starting with the null model, add one variable at a time until you bottom out on the AIC score.
#dont forget make the lower and upper a LIST type.
step(null2model, scope = list(lower = null2model, upper = full2model), direction = "forward")
predprob <- fitted(rich.out) # get predicted probabilities
predprob <- fitted(glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
#load the data and review a summary of the variables.
library(DS705data)
data("rowtime")
summary(rowtime)
#import the regsubsets() function from the leaps library
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(racetime~.,data = rowtime, nvmax = 8)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
#start with a "full" model denoted by y~.
#then do a backward step to remove variables from the equation until a best is reached.
step(lm(racetime~., data=rowtime), direction = "backward")
#to begin the "forward" step function, we set a "null" model which is the y~1
nullmodel = lm(racetime~1, data = rowtime)
#we set a "full" model to be the "cap" for the forward step function y~.
fullmodel = lm(racetime~., data = rowtime)
#starting with the null model, add variables one at a time and test their impact, within the bounds of the lower and upper limits.
step(nullmodel,scope = list(lower=nullmodel, upper=fullmodel), direction = "forward")
#regsubsets w/8 variables
extractAIC(lm(formula = racetime~calfcir+biceps+bestvj+legpower+meso+ecto+expvarsity+preexper, data=rowtime))
#step backward (9 variables)
extractAIC(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
#step forward (8 variables)
extractAIC(lm(formula = racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj, data=rowtime))
#loading the car package for the vif() function
library(car)
#checking the vif scores of the independent variables. greater than 10 suggests a collinearity problem.
vif(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
# The code in this chunk is provided for students
library(DS705data)
data("rowtime")
pairs(rowtime[c(1,2,3,4)])
pairs(rowtime[c(1,5,6,7)])
pairs(rowtime[c(1,8,9,10)])
pairs(rowtime[c(1,11,12,13,14)])
pairs(rowtime[c(1,15,16,17,18)])
#storing the results of the forward step() model into a variable
model = lm(racetime~estffm + expvarsity + tall + preexper + biceps + meso + calfcir + bestvj, data = rowtime)
#using that model as a starting point, check the combination of all interaction terms to see if they add additional value.
#the first . means all variables. the * means interaction, and the second . means all teams. So to summarize, check all terms interactions with all terms.
step(model, scope = .~.*., direction = "forward")
#create a summary of the new model with the two additional interaction terms.
model_f = lm(racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj+tall:calfcir+estffm:bestvj, data=rowtime)
summary(model_f)
#create a histogram, qqplot, and boxplot of the residuals.
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, ylab = "Count", main = "Distribution of Residuals for Model_F")
#check normality of the residuals with the shapiro test.
shapiro.test(model_f$residuals)
#create a residual plot of residuals vs. fitted values.
plot(model_f$fitted.values, model_f$residuals, xlab="Fitted Values", ylab = "Residuals", main = "Residual Plot for Model_F")
#load in the lmtest library
library(lmtest)
#run the equal variance test.
bptest(model_f)
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
#building a full model (for the upper limit)
full2model = glm(RICH~., data = farmpond, family = "binomial")
#building a null model (or starting point, for the lower bounds) so the "step forward" can add to it.
null2model = glm(RICH~1, data = farmpond, family = "binomial")
#starting with the null model, add one variable at a time until you bottom out on the AIC score.
#dont forget make the lower and upper a LIST type.
step(null2model, scope = list(lower = null2model, upper = full2model), direction = "forward")
predprob <- fitted(glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.8  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.9  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.95  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
#load the data and review a summary of the variables.
library(DS705data)
data("rowtime")
summary(rowtime)
#import the regsubsets() function from the leaps library
library(leaps)
#using the "full" number of variables denoted by y~., step forward until you've determine the best model with 8 predictors.
#nvmax is the number of variables to step toward. Obviously there may be increases or decreases to adjusted r2, so it might be best to allow it to go all the way to the max number of variables within the dataset and then just look at which one gives the best adjusted r2 (or whatever metric were interested in as the grading criteria).
allmodels=regsubsets(racetime~.,data = rowtime, nvmax = 8)
#because "all" 8 of the models are stored, run summary to see the output.
summary(allmodels)
#the summary is ok, but this plot is where you can really see what model gives the best adjusted r2 measure.
plot(allmodels, scale = "adjr2")
#start with a "full" model denoted by y~.
#then do a backward step to remove variables from the equation until a best is reached.
step(lm(racetime~., data=rowtime), direction = "backward")
#to begin the "forward" step function, we set a "null" model which is the y~1
nullmodel = lm(racetime~1, data = rowtime)
#we set a "full" model to be the "cap" for the forward step function y~.
fullmodel = lm(racetime~., data = rowtime)
#starting with the null model, add variables one at a time and test their impact, within the bounds of the lower and upper limits.
step(nullmodel,scope = list(lower=nullmodel, upper=fullmodel), direction = "forward")
#regsubsets w/8 variables
extractAIC(lm(formula = racetime~calfcir+biceps+bestvj+legpower+meso+ecto+expvarsity+preexper, data=rowtime))
#step backward (9 variables)
extractAIC(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
#step forward (8 variables)
extractAIC(lm(formula = racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj, data=rowtime))
#loading the car package for the vif() function
library(car)
#checking the vif scores of the independent variables. greater than 10 suggests a collinearity problem.
vif(lm(formula = racetime~tall+calfcir+biceps+estfm+bestvj+legpower+meso+expvarsity+preexper, data=rowtime))
# The code in this chunk is provided for students
library(DS705data)
data("rowtime")
pairs(rowtime[c(1,2,3,4)])
pairs(rowtime[c(1,5,6,7)])
pairs(rowtime[c(1,8,9,10)])
pairs(rowtime[c(1,11,12,13,14)])
pairs(rowtime[c(1,15,16,17,18)])
#storing the results of the forward step() model into a variable
model = lm(racetime~estffm + expvarsity + tall + preexper + biceps + meso + calfcir + bestvj, data = rowtime)
#using that model as a starting point, check the combination of all interaction terms to see if they add additional value.
#the first . means all variables. the * means interaction, and the second . means all teams. So to summarize, check all terms interactions with all terms.
step(model, scope = .~.*., direction = "forward")
#create a summary of the new model with the two additional interaction terms.
model_f = lm(racetime~estffm+expvarsity+tall+preexper+biceps+meso+calfcir+bestvj+tall:calfcir+estffm:bestvj, data=rowtime)
summary(model_f)
#create a histogram, qqplot, and boxplot of the residuals.
hist(model_f$residuals, xlab="Residuals", ylab = "Count", main = "Distribution of Residuals for Model_F")
qqnorm(model_f$residuals, main = "QQ Plot Residuals of Model_F")
qqline(model_f$residuals)
boxplot(model_f$residuals, ylab = "Count", main = "Distribution of Residuals for Model_F")
#check normality of the residuals with the shapiro test.
shapiro.test(model_f$residuals)
#create a residual plot of residuals vs. fitted values.
plot(model_f$fitted.values, model_f$residuals, xlab="Fitted Values", ylab = "Residuals", main = "Residual Plot for Model_F")
#load in the lmtest library
library(lmtest)
#run the equal variance test.
bptest(model_f)
#load the farmpond dataset and build a logistic regression model for the RICH variable using all the other predictor variables.
data("farmpond")
#building a full model (for the upper limit)
full2model = glm(RICH~., data = farmpond, family = "binomial")
#building a null model (or starting point, for the lower bounds) so the "step forward" can add to it.
null2model = glm(RICH~1, data = farmpond, family = "binomial")
#starting with the null model, add one variable at a time until you bottom out on the AIC score.
#dont forget make the lower and upper a LIST type.
step(null2model, scope = list(lower = null2model, upper = full2model), direction = "forward")
model2 = glm(RICH~ COND + TOTNITR + FISH, data = farmpond, family = "binomial")
predprob <- fitted(model2) # get predicted probabilities
threshhold <- 0.5  # Set Y=1 when predicted probability exceeds this
predRICH <- cut(predprob, breaks=c(-Inf, threshhold, Inf),
labels=c("Sp Rich<4", "Sp Rich>=4"))  # Y=1 is "Sp Rich>=4" here
cTab <- table(farmpond$RICH, predRICH)
addmargins(cTab)
p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
print(paste('Proportion correctly predicted = ', p))
round(fitted(model2),2)
#load the function from the pscl package
library(pscl)
#using the pR2 function to get the "McFaddens pseudo R2" value. This is like an R2 value for linear regression, but for logistic.
pR2(model2)[4]
#load the function from the ResourceSelection package
library(ResourceSelection)
#conduct the Hoslem-Lemeshow GOF test for logistic regression. This basically tests if the model is a good fit to the data.
#null = is a good fit; alt = is not a good fit.
hoslem.test(farmpond$RICH, fitted(model2), g=5)
install.packages("caTools")
knitr::opts_chunk$set(fig.width = 4, fig.height = 4)
lapply(c("readr","dplyr","car","mice","ggformula","ggpubr","caTools"), require, character.only = TRUE)
#load the data
loans = read_csv("loans50k.csv")
loans = loans[loans$status %in% c("Fully Paid", "Charged Off", "Default"),]
loans = loans %>% mutate(outcome = as.factor(if_else(status == "Fully Paid","Good","Bad")))
loans = subset(loans, select = -status)
loans = subset(loans, select = -c(loanID,employment,verified,state,debtIncRat,revolRatio,totalAcc,totalPaid,bcRatio))
str(loans)
loans = mutate_at(loans, vars(term,grade,length,home,reason), as.factor)
par(mfrow=c(2,3),mar=c(4,3,3,1))
barplot(table(loans$term), main = "Loan Term")
barplot(table(loans$grade), main = "Loan Grade")
barplot(table(loans$length), las=2, main = "Employment Length")
barplot(table(loans$home), main = "Living Type")
barplot(table(loans$reason), las=2, cex.names = 0.9, main = "Loan Reason")
loans$grade = recode(loans$grade,"c('E','F','G')='E or less'")
lapply(c("readr","dplyr","car","mice","ggformula","ggpubr","caTools"), require, character.only = TRUE)
#load the data
loans = read_csv("loans50k.csv")
loans = loans[loans$status %in% c("Fully Paid", "Charged Off", "Default"),]
loans = loans %>% mutate(outcome = as.factor(if_else(status == "Fully Paid","Good","Bad")))
loans = subset(loans, select = -status)
loans = subset(loans, select = -c(loanID,employment,verified,state,debtIncRat,revolRatio,totalAcc,totalPaid,bcRatio))
str(loans)
loans = mutate_at(loans, vars(term,grade,length,home,reason), as.factor)
par(mfrow=c(2,3),mar=c(4,3,3,1))
barplot(table(loans$term), main = "Loan Term")
barplot(table(loans$grade), main = "Loan Grade")
barplot(table(loans$length), las=2, main = "Employment Length")
barplot(table(loans$home), main = "Living Type")
barplot(table(loans$reason), las=2, cex.names = 0.9, main = "Loan Reason")
loans$grade = recode(loans$grade,"c('E','F','G')='E or less'")
lapply(c("readr","dplyr","car","mice","ggformula","ggpubr"), require, character.only = TRUE)
knitr::opts_chunk$set(fig.width = 4, fig.height = 4)
lapply(c("readr","dplyr","car","mice","ggformula","ggpubr"), require, character.only = TRUE)
#load the data
loans = read_csv("loans50k.csv")
loans = loans[loans$status %in% c("Fully Paid", "Charged Off", "Default"),]
loans = loans %>% mutate(outcome = as.factor(if_else(status == "Fully Paid","Good","Bad")))
loans = subset(loans, select = -status)
loans = subset(loans, select = -c(loanID,employment,verified,state,debtIncRat,revolRatio,totalAcc,totalPaid,bcRatio))
str(loans)
loans = mutate_at(loans, vars(term,grade,length,home,reason), as.factor)
par(mfrow=c(2,3),mar=c(4,3,3,1))
barplot(table(loans$term), main = "Loan Term")
barplot(table(loans$grade), main = "Loan Grade")
barplot(table(loans$length), las=2, main = "Employment Length")
barplot(table(loans$home), main = "Living Type")
barplot(table(loans$reason), las=2, cex.names = 0.9, main = "Loan Reason")
loans$grade = recode(loans$grade,"c('E','F','G')='E or less'")
loans$length = recode(loans$length,"c('< 1 year','1 year','2 years','3 years','4 years')='0-4 years';c('5 years','6 years','7 years','8 years','9 years')='5-9 years'")
